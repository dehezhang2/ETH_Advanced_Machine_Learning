{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import (SimpleImputer,KNNImputer)\n",
    "from sklearn.ensemble import (RandomForestRegressor, IsolationForest)\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, normalize\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values_KNN(X, X_test): \n",
    "    #normalization\n",
    "    X_std = np.nanstd(X,axis=0,keepdims=True)\n",
    "    X_ave = np.nanmean(X,axis=0,keepdims=True)\n",
    "    \n",
    "    X_norma = (X-X_ave)/X_std\n",
    "    X_test_norma = (X_test-X_ave)/X_std\n",
    "\n",
    "    imputer = KNNImputer(missing_values=np.nan, n_neighbors=75, weights = 'distance')\n",
    "    X_norma_fixed = imputer.fit_transform(X_norma)\n",
    "    X_test_norma_fixed = imputer.fit_transform(X_test_norma)\n",
    "\n",
    "    return X_norma_fixed, X_test_norma_fixed\n",
    "\n",
    "# def fill_missing_values_mean(X, X_test):\n",
    "#     imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "#     imp.fit(X)\n",
    "#     X = imp.transform(X)\n",
    "#     imp.fit(X_test)\n",
    "#     X_test = imp.transform(X_test)\n",
    "#     return X, X_test\n",
    "\n",
    "def fill_missing_values_median(X):\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    imp.fit(X)\n",
    "    X = imp.transform(X)\n",
    "    return X\n",
    "\n",
    "def remove_outliers_XY(X, y, y_additional_degree):\n",
    "#     print(\"IsolationForest-Traing data shape before removed: {}\".format(X.shape))\n",
    "    \n",
    "    Y = y\n",
    "    for degree in y_additional_degree:\n",
    "        Y = np.c_[Y, y**degree]\n",
    "        \n",
    "    Z = np.c_[X, Y]\n",
    "    iforest = IsolationForest(max_samples=200, random_state=1, contamination=0.005)\n",
    "    iforest.fit(Z)\n",
    "    iforest_outlier_pred = iforest.predict(Z)\n",
    "    \n",
    "    Z = np.c_[X, Y]\n",
    "    local = LocalOutlierFactor(n_neighbors=150, contamination=0.005)\n",
    "    local.fit(Z)\n",
    "    local_outlier_pred = local.fit_predict(Z)\n",
    "\n",
    "    mask = np.logical_and((iforest_outlier_pred!=-1), (local_outlier_pred!=-1))\n",
    "#     X , y = X[mask, :], y[mask]\n",
    "#     print(\"IsolationForest-Traing data shape after removed: {}\".format(X.shape))\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "def find_missing_value_and_move_outliers(X, y, X_test,y_additional_degree):\n",
    "    print(\"Traing data shape before impute and outlier remove: {}\".format(X.shape))\n",
    "    print(\"Testing data shape before impute and outlier remove: {}\".format(X_test.shape))\n",
    "    X_nan = np.isnan(X)  \n",
    "    X_median = fill_missing_values_median(X)\n",
    "    print(X_median.shape)\n",
    "    \n",
    "    IstInLiers = remove_outliers_XY(X_median, y, y_additional_degree)\n",
    "    X_median = X_median[IstInLiers, :]\n",
    "    X_nan = X_nan[IstInLiers, :]\n",
    "    y = y[IstInLiers]\n",
    "    print(X_median.shape)\n",
    "    print(X_nan.shape)    \n",
    "    X_median[X_nan] = np.nan\n",
    "    \n",
    "    X_KNN,X_test_KNN = fill_missing_values_KNN(X_median, X_test)\n",
    "    print(\"Traing data shape after impute and outlier remove: {}\".format(X_KNN.shape))\n",
    "    print(\"Testing data shape after impute and outlier remove: {}\".format(X_test_KNN.shape))\n",
    "    \n",
    "    return X_KNN,X_test_KNN,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X, y, X_test, feature_num=100):\n",
    "    scaler = StandardScaler().fit(X, y)\n",
    "    X = scaler.transform(X)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_jobs=-1, n_estimators=75, random_state=1)\n",
    "#     rf = ExtraTreesRegressor(n_jobs=-1, max_depth=None, n_estimators=180, random_state=1, min_samples_split=3, max_features=None)\n",
    "    rf.fit(X, y)\n",
    "    indices = np.asarray(list(rf.feature_importances_)).argsort()[-feature_num:][::-1]\n",
    "    \n",
    "    X = np.take(X, indices, axis = 1)\n",
    "    X_test = np.take(X_test, indices, axis = 1)\n",
    "    \n",
    "    return X, X_test\n",
    "def auto_feature_extraction(X, y, X_test):\n",
    "    fsel = FeatureSelector(verbose=1)\n",
    "    \n",
    "    feature_names = [str(i) for i in range(0,X.shape[1])]\n",
    "    X_pd = pd.DataFrame(X, columns=feature_names)\n",
    "    new_X = fsel.fit_transform(X_pd, y)\n",
    "    print(\"len of columns:\", len(new_X.columns))\n",
    "    print(new_X.columns)\n",
    "    index_chosen = [int(new_X.columns[i]) for i in range(0,len(new_X.columns))]\n",
    "    return X[:,index_chosen],X_test[:,index_chosen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = pd.read_csv('X_train.csv')\n",
    "y_train_data = pd.read_csv('y_train.csv')\n",
    "X_test_data = pd.read_csv('X_test.csv')\n",
    "\n",
    "indices_test = np.array(X_test_data)[:,0]\n",
    "X_test = np.array(X_test_data)[:,1:]\n",
    "y_train = np.array(y_train_data)[:,1]\n",
    "X_train = np.array(X_train_data)[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imputation of Missing Values\n",
    "* [Reference](https://scikit-learn.org/stable/modules/impute.html)\n",
    "* We use median of column instead of mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_missing_indices = X_train[X_train==np]\n",
    "# X_train, X_test = fill_missing_values(X_train, X_test)\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Outlier Detection\n",
    "* [reference_sklearn](https://scikit-learn.org/stable/modules/outlier_detection.html)\n",
    "* [reference_in_detail](https://practicaldatascience.co.uk/machine-learning/how-to-use-the-isolation-forest-model-for-outlier-detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing data shape before impute and outlier remove: (1212, 832)\n",
      "Testing data shape before impute and outlier remove: (776, 832)\n",
      "(1212, 832)\n",
      "(1198, 832)\n",
      "(1198, 832)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/qjssdfqd3f52ltwv16hkg4kh0000gn/T/ipykernel_31851/4222198039.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_norma = (X-X_ave)/X_std\n",
      "/var/folders/df/qjssdfqd3f52ltwv16hkg4kh0000gn/T/ipykernel_31851/4222198039.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_test_norma = (X_test-X_ave)/X_std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing data shape after impute and outlier remove: (1198, 828)\n",
      "Testing data shape after impute and outlier remove: (776, 828)\n"
     ]
    }
   ],
   "source": [
    "# X_train,y_train = remove_outliers(X_train,y_train)\n",
    "X_train_processed, X_test_processed, y_processed = find_missing_value_and_move_outliers(X_train, y_train, X_test,[0.5,1.5,2,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_feature_extraction(X, y, X_test):\n",
    "    fsel = FeatureSelector(verbose=1)\n",
    "    \n",
    "    feature_names = [str(i) for i in range(0,X.shape[1])]\n",
    "    X_pd = pd.DataFrame(X, columns=feature_names)\n",
    "    new_X = fsel.fit_transform(X_pd, y)\n",
    "    print(\"len of columns:\", len(new_X.columns))\n",
    "    print(new_X.columns)\n",
    "    index_chosen = [int(new_X.columns[i]) for i in range(0,len(new_X.columns))]\n",
    "    return X[:,index_chosen],X_test[:,index_chosen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature_from_batch1, X_test_feature_from_batch1 = X_train_processed, X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[featsel] Scaling data..."
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nInternal error at <numba.typeinfer.CallConstraint object at 0x7fdc5ef6fe20>.\nFailed in nopython mode pipeline (step: nopython frontend)\nUnsupported constraint encountered: raise $24load_global.0.175\n\nFile \"../../../../../anaconda3/envs/aml_project/lib/python3.8/site-packages/autofeat/nb_utils.py\", line 12:\ndef nb_apply_along_axis(func1d, axis, arr):\n    <source elided>\n    assert arr.ndim == 2\n    assert axis in [0, 1]\n    ^\n\n[1] During: resolving callee type: type(CPUDispatcher(<function nb_nanmean at 0x7fdc5e981280>))\n[2] During: typing of call at /Users/zdh/anaconda3/envs/aml_project/lib/python3.8/site-packages/autofeat/nb_utils.py (36)\n\nEnable logging at debug level for details.\n\nFile \"../../../../../anaconda3/envs/aml_project/lib/python3.8/site-packages/autofeat/nb_utils.py\", line 36:\ndef nb_standard_scale(array):\n    return (array - nb_nanmean(array, 0)) / nb_nanstd(array, 0)\n    ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/df/qjssdfqd3f52ltwv16hkg4kh0000gn/T/ipykernel_31851/1462820791.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_feature_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_feature_from_batch1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_test__feature_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_feature_from_batch1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mX_feature_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test__feature_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_feature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_feature_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test__feature_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/df/qjssdfqd3f52ltwv16hkg4kh0000gn/T/ipykernel_31851/3048158342.py\u001b[0m in \u001b[0;36mauto_feature_extraction\u001b[0;34m(X, y, X_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnew_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"len of columns:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/autofeat/featsel.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0mnew_X\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgood\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/autofeat/featsel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# do the feature selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgood_cols_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatsel_runs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/autofeat/featsel.py\u001b[0m in \u001b[0;36mselect_features\u001b[0;34m(df, target, featsel_runs, keep, problem_type, n_jobs, verbose)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mdf_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_standard_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mtarget_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_standard_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/numba/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nInternal error at <numba.typeinfer.CallConstraint object at 0x7fdc5ef6fe20>.\nFailed in nopython mode pipeline (step: nopython frontend)\nUnsupported constraint encountered: raise $24load_global.0.175\n\nFile \"../../../../../anaconda3/envs/aml_project/lib/python3.8/site-packages/autofeat/nb_utils.py\", line 12:\ndef nb_apply_along_axis(func1d, axis, arr):\n    <source elided>\n    assert arr.ndim == 2\n    assert axis in [0, 1]\n    ^\n\n[1] During: resolving callee type: type(CPUDispatcher(<function nb_nanmean at 0x7fdc5e981280>))\n[2] During: typing of call at /Users/zdh/anaconda3/envs/aml_project/lib/python3.8/site-packages/autofeat/nb_utils.py (36)\n\nEnable logging at debug level for details.\n\nFile \"../../../../../anaconda3/envs/aml_project/lib/python3.8/site-packages/autofeat/nb_utils.py\", line 36:\ndef nb_standard_scale(array):\n    return (array - nb_nanmean(array, 0)) / nb_nanstd(array, 0)\n    ^\n"
     ]
    }
   ],
   "source": [
    "from autofeat import FeatureSelector, AutoFeatRegressor\n",
    "split_num = 20\n",
    "split_size = int(X_test_feature_from_batch1.shape[1]/split_num)\n",
    "first_flag = 1\n",
    "for i in range(0,split_num):\n",
    "    split_index = [j for j in range(i*split_size,min((i+1)*split_size,X_test_feature_from_batch1.shape[1]))]\n",
    "    X_feature_subset = X_feature_from_batch1[:,split_index]\n",
    "    X_test__feature_subset = X_test_feature_from_batch1[:,split_index]\n",
    "    X_feature_subset, X_test__feature_subset = auto_feature_extraction(X_feature_subset, y_processed, X_test__feature_subset)\n",
    "\n",
    "    if(first_flag):\n",
    "        first_flag = 0\n",
    "        X_feature_from_batch2 = X_feature_subset\n",
    "        X_test_feature_from_batch2 = X_test__feature_subset\n",
    "    else:\n",
    "\n",
    "        X_feature_from_batch2 = np.hstack((X_feature_from_batch2,X_feature_subset))\n",
    "        X_test_feature_from_batch2 = np.hstack((X_test_feature_from_batch2,X_test__feature_subset))\n",
    "print(\"shape of X_feature_from_batch2:\",X_test_feature_from_batch2.shape)\n",
    "print(\"shape of X_test_feature_from_batch2:\",X_test_feature_from_batch2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature_from_batch3, X_test_feature_from_batch3 = select_features(X_feature_from_batch2, y_processed, X_test_feature_from_batch2,feature_num = 60)\n",
    "print(\"shape of X_feature_from_batch3: \", X_feature_from_batch3.shape)\n",
    "print(\"shape of X_test_feature_from_batch3: \", X_test_feature_from_batch3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def custom_r2(prediction, train_data):\n",
    "    \"\"\"Regular r2 cost function returned as a tuple to be used with lgb\"\"\"\n",
    "    labels = train_data.get_label()\n",
    "    return 'r2', r2_score(labels, prediction), True\n",
    "\n",
    "def fit_model_and_pred(degree, X_train, y_train, X_val, y_val, X_test):\n",
    "   \n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'num_leaves': 1700,\n",
    "        'learning_rate': 0.025,\n",
    "        'max_depth': 11,\n",
    "        'n_estimators': 1000,\n",
    "        'min_child_weight': 1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'feature_fraction': 0.5,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'num_iterations':600,\n",
    "    }\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=500,\n",
    "                    feval=custom_r2,\n",
    "                    valid_sets={lgb_train, lgb_eval},\n",
    "                    early_stopping_rounds=100\n",
    "                   )\n",
    "\n",
    "    y_pred = gbm.predict(X_test) \n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def train_k_fold(X, y, fold_num=10):\n",
    "    kf = KFold(n_splits=fold_num, random_state=None, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "    test_score = 0.0\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[test_index]\n",
    "        y_train, y_val = y[train_index], y[test_index]\n",
    "\n",
    "        y_pred = fit_model_and_pred(1, X_train, y_train, X_val, y_val, X_val)\n",
    "        score = r2_score(y_val, y_pred)\n",
    "\n",
    "        print('The obtained validation r2 score is : ',score)\n",
    "        test_score += score\n",
    "    print(\"Validation score: %f\"%(test_score/fold_num))\n",
    "    \n",
    "def train_k_fold_predict(X, y,X_test, fold_num=10):\n",
    "    kf = KFold(n_splits=fold_num, random_state=None, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "    test_score = 0.0\n",
    "    y_test_predict = np.zeros(X_test.shape[0])\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[test_index]\n",
    "        y_train, y_val = y[train_index], y[test_index]\n",
    "        score = r2_score(y_val, fit_model_and_pred(1, X_train, y_train, X_val, y_val, X_val))\n",
    "        test_score += score\n",
    "        \n",
    "        y_pred = fit_model_and_pred(1, X_train, y_train, X_val, y_val, X_test)\n",
    "        y_test_predict += y_pred\n",
    "        \n",
    "    print(\"Validation score: %f\"%(test_score/fold_num))\n",
    "    return y_test_predict/fold_num\n",
    "\n",
    "# 以下是树训练模型\n",
    "# def fit_model_and_pred(X_train, y_train, X_val, y_val, X_test):\n",
    "#     model = ExtraTreesRegressor(n_jobs=1, max_depth=None, n_estimators=195, random_state=0, min_samples_split=2, max_features=None)\n",
    "\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     y_val_pred = model.predict(X_val)\n",
    "#     score = r2_score(y_val, y_val_pred)\n",
    "    \n",
    "#     y_pred = model.predict(X_test) \n",
    "    \n",
    "#     return score, y_pred\n",
    "\n",
    "\n",
    "# def train_k_fold(X, y, fold_num=10):\n",
    "#     kf = KFold(n_splits=fold_num, random_state=None, shuffle=False)\n",
    "#     kf.get_n_splits(X)\n",
    "#     test_score = 0.0\n",
    "    \n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#         X_train, X_val = X[train_index], X[test_index]\n",
    "#         y_train, y_val = y[train_index], y[test_index]\n",
    "\n",
    "#         y_pred = fit_model_and_pred(1, X_train, y_train, X_val, y_val, X_val)\n",
    "#         score = r2_score(y_val, y_pred)\n",
    "\n",
    "#         print('The obtained validation r2 score is : ',score)\n",
    "#         test_score += score\n",
    "#     print(\"Validation score: %f\"%(test_score/fold_num))\n",
    "    \n",
    "\n",
    "# def train_k_fold_predict(X, y, X_test, fold_num=10):\n",
    "#     kf = KFold(n_splits=fold_num)\n",
    "#     kf.get_n_splits(X)\n",
    "#     y_test_predict = np.zeros(X_test.shape[0])\n",
    "#     cnt = 0\n",
    "#     val_score = 0.0\n",
    "    \n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#         X_train, X_val = X[train_index], X[test_index]\n",
    "#         y_train, y_val = y[train_index], y[test_index]\n",
    "\n",
    "#         score, y_pred = fit_model_and_pred(X_train, y_train, X_val, y_val, X_test)\n",
    "#         val_score += score\n",
    "#         if(score > 0.7):\n",
    "#             y_test_predict += y_pred\n",
    "#             cnt += 1\n",
    "#     return val_score/fold_num, y_test_predict/cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_k_fold(X_feature_from_batch3,y_processed) #Knn with std and feature num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = train_k_fold_predict(X_feature_from_batch3,y_processed,X_test_feature_from_batch3)\n",
    "final_res = np.vstack((indices_test, Y_test_pred)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(final_res).to_csv(\"our_result.csv\", header = [\"id\", \"y\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
