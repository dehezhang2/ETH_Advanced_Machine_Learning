{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zdh/anaconda3/envs/aml_project/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import (SimpleImputer,KNNImputer)\n",
    "from missingpy import MissForest\n",
    "from sklearn.ensemble import (RandomForestRegressor, IsolationForest)\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, normalize\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(X, n_neighbors = 75, method=\"KNN\"): \n",
    "    \n",
    "    # normalization\n",
    "    X_std = np.nanstd(X,axis=0,keepdims=True)\n",
    "    X_ave = np.nanmean(X,axis=0,keepdims=True)\n",
    "    X_norma = (X-X_ave)/X_std\n",
    "    \n",
    "    # use KNNImputer\n",
    "    imputer = KNNImputer(missing_values=np.nan, n_neighbors=n_neighbors, weights = 'distance') if method==\"KNN\"\\\n",
    "        else SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    \n",
    "    X_norma_fixed = imputer.fit_transform(X_norma)\n",
    "    \n",
    "    return X_norma_fixed\n",
    "\n",
    "# def fill_missing_values(X, n_neighbors = 75, method=\"KNN\"): \n",
    "    \n",
    "#     # normalization\n",
    "#     X_std = np.nanstd(X,axis=0,keepdims=True)\n",
    "#     X_ave = np.nanmean(X,axis=0,keepdims=True)\n",
    "#     X_norma = (X-X_ave)/X_std\n",
    "    \n",
    "#     imputer = MissForest(max_iter=10, missing_values=np.nan, n_estimators=2, max_depth=4, min_samples_split=2)\n",
    "#     X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "#     return X_imputed\n",
    "\n",
    "def remove_outliers(X, y):\n",
    "    print(\"IsolationForest-Traing data shape before removed: {}\".format(X.shape))\n",
    "    Z = np.c_[X, y]\n",
    "    iforest = IsolationForest(max_samples=200, random_state=1, contamination=0.005)\n",
    "    iforest.fit(Z)\n",
    "    iforest_outlier_pred = iforest.predict(Z)\n",
    "    \n",
    "    Z = np.c_[X, y]\n",
    "    local = LocalOutlierFactor(n_neighbors=150, contamination=0.005)\n",
    "    local.fit(Z)\n",
    "    local_outlier_pred = local.fit_predict(Z)\n",
    "\n",
    "    mask = np.logical_and((iforest_outlier_pred!=-1), (local_outlier_pred!=-1))\n",
    "    X , y = X[mask, :], y[mask]\n",
    "    print(\"IsolationForest-Traing data shape after removed: {}\".format(X.shape))\n",
    "    return X, y\n",
    "\n",
    "def select_features(X, y, X_test, feature_num=50):\n",
    "    rf = RandomForestRegressor(n_jobs=-1, n_estimators=80, random_state=1)\n",
    "    rf.fit(X, y)\n",
    "    indices = np.asarray(list(rf.feature_importances_)).argsort()[-feature_num:][::-1]\n",
    "    \n",
    "    X = np.take(X, indices, axis = 1)\n",
    "    X_test = np.take(X_test, indices, axis = 1)\n",
    "    \n",
    "    return X, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = pd.read_csv('X_train.csv')\n",
    "y_train_data = pd.read_csv('y_train.csv')\n",
    "X_test_data = pd.read_csv('X_test.csv')\n",
    "\n",
    "indices_test = np.array(X_test_data)[:,0]\n",
    "X_test = np.array(X_test_data)[:,1:]\n",
    "y_train = np.array(y_train_data)[:,1]\n",
    "X_train = np.array(X_train_data)[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imputation of Missing Values\n",
    "* [Reference](https://scikit-learn.org/stable/modules/impute.html)\n",
    "* We use median of column instead of mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/qjssdfqd3f52ltwv16hkg4kh0000gn/T/ipykernel_29649/289236912.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_norma = (X-X_ave)/X_std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/qjssdfqd3f52ltwv16hkg4kh0000gn/T/ipykernel_29649/289236912.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_norma = (X-X_ave)/X_std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "(1212, 832)\n",
      "(776, 832)\n"
     ]
    }
   ],
   "source": [
    "X_train_missing_indices = X_train[X_train==np]\n",
    "X_train = fill_missing_values(X_train, n_neighbors=75)\n",
    "X_test = fill_missing_values(X_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Outlier Detection\n",
    "* [reference_sklearn](https://scikit-learn.org/stable/modules/outlier_detection.html)\n",
    "* [reference_in_detail](https://practicaldatascience.co.uk/machine-learning/how-to-use-the-isolation-forest-model-for-outlier-detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest-Traing data shape before removed: (1212, 832)\n",
      "IsolationForest-Traing data shape after removed: (1198, 832)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train = remove_outliers(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing data shape after selection: (1198, 50)\n",
      "Testing data shape after selection: (776, 50)\n"
     ]
    }
   ],
   "source": [
    "# X, X_test = feature_reduction(X, X_test,750)\n",
    "X_train, X_test = select_features(X_train, y_train, X_test,feature_num = 50)\n",
    "print(\"Traing data shape after selection: {}\".format(X_train.shape))\n",
    "print(\"Testing data shape after selection: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_and_pred(X_train, y_train, X_val, y_val, X_test):\n",
    "    model = ExtraTreesRegressor(n_jobs=1, max_depth=None, n_estimators=190, random_state=0, min_samples_split=3, max_features=None)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val)\n",
    "    score = r2_score(y_val, y_val_pred)\n",
    "    \n",
    "    y_pred = model.predict(X_test) \n",
    "    \n",
    "    return score, y_pred\n",
    "\n",
    "def train_k_fold(X, y, fold_num=10):\n",
    "    kf = KFold(n_splits=fold_num, shuffle=False)\n",
    "    kf.get_n_splits(X)\n",
    "    test_score = 0.0\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[test_index]\n",
    "        y_train, y_val = y[train_index], y[test_index]\n",
    "\n",
    "        score, y_pred = fit_model_and_pred(X_train, y_train, X_val, y_val, X_val)\n",
    "\n",
    "        print('The obtained validation r2 score is : ',score)\n",
    "        test_score += score\n",
    "    print(\"Validation score: %f\"%(test_score/fold_num))\n",
    "    \n",
    "def train_k_fold_predict(X, y, X_test, fold_num=10):\n",
    "    kf = KFold(n_splits=fold_num)\n",
    "    kf.get_n_splits(X)\n",
    "    y_test_predict = np.zeros(X_test.shape[0])\n",
    "    cnt = 0\n",
    "    val_score = 0.0\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[test_index]\n",
    "        y_train, y_val = y[train_index], y[test_index]\n",
    "\n",
    "        score, y_pred = fit_model_and_pred(X_train, y_train, X_val, y_val, X_test)\n",
    "        val_score += score\n",
    "        if(score > 0.7):\n",
    "            y_test_predict += y_pred\n",
    "            cnt += 1\n",
    "    return val_score/fold_num, y_test_predict/cnt\n",
    "\n",
    "def train_random_iterations(X, y, X_test, iterations=100):\n",
    "    y_test_predict = np.zeros(X_test.shape[0])\n",
    "    y_pred_best = np.zeros(X_test.shape[0])\n",
    "    cnt = 0\n",
    "    best_score = -10000\n",
    "    \n",
    "    for i in tqdm(range(100)):\n",
    "        score, y_pred = train_k_fold_predict(X, y, X_test)\n",
    "        if(score > best_score):\n",
    "            best_score = score\n",
    "            y_pred_best = y_pred\n",
    "            \n",
    "    print(\"Total number of prediction used: {}\".format(cnt))\n",
    "    return y_pred_best\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The obtained validation r2 score is :  0.7200893762939793\n",
      "The obtained validation r2 score is :  0.6568493326629549\n",
      "The obtained validation r2 score is :  0.5174091632311921\n",
      "The obtained validation r2 score is :  0.6617141313707703\n",
      "The obtained validation r2 score is :  0.587016487193833\n",
      "The obtained validation r2 score is :  0.5015825993369158\n",
      "The obtained validation r2 score is :  0.5890074807011265\n",
      "The obtained validation r2 score is :  0.5905130905447111\n",
      "The obtained validation r2 score is :  0.7091314953017072\n",
      "The obtained validation r2 score is :  0.6097824145947575\n",
      "Validation score: 0.614310\n"
     ]
    }
   ],
   "source": [
    "train_k_fold(X_train,y_train) #Knn with std and feature num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_pred = train_random_iterations(X_train, y_train, X_test)\n",
    "# final_res = np.vstack((indices_test, y_test_pred)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(final_res).to_csv(\"our_result.csv\", header = [\"id\", \"y\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
