{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, targets):\n",
    "    ious = []\n",
    "    for p, t in zip(predictions, targets):\n",
    "        assert p['name'] == t['name']\n",
    "        prediction = np.array(p['prediction'], dtype=bool)\n",
    "        target = np.array(t['label'], dtype=bool)\n",
    "\n",
    "        assert target.shape == prediction.shape\n",
    "        overlap = prediction*target\n",
    "        union = prediction + target\n",
    "\n",
    "        ious.append(overlap.sum()/float(union.sum()))\n",
    "    \n",
    "    print(\"Median IOU: \", np.median(ious))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = load_zipped_pickle(\"train.pkl\")\n",
    "test_data = load_zipped_pickle(\"test.pkl\")\n",
    "samples = load_zipped_pickle(\"sample.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据结构：  \n",
    "    train_data[1-65]包含65个病人的数据, 前46个是amateur数据， 后19个是expert数据  \n",
    "    train_data[1]['video','label','dataset'...] , video是图片数组， label是MV mask，dataset代表是amateur还是expert  \n",
    "    train_data[1]['video'] shape: [IMG_WIDTH, IMG_HEIGHT, FRAME NUM]， label也一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img = train_data[60]['label'][:,:,24]\n",
    "# zero_img = np.zeros(test_img.shape)\n",
    "# zero_img[test_img] = 255\n",
    "# zero_img_resize = cv2.resize(zero_img, (1000,1000))\n",
    "# zero_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"mask\", zero_img_resize)\n",
    "  \n",
    "# cv2.waitKey(0) \n",
    "\n",
    "# cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 样本图片大小\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到含有标记的帧\n",
    "def is_labeled(mask_list):\n",
    "    \n",
    "    label_index = []\n",
    "    for i in range((mask_list).shape[2]):\n",
    "        if(True in mask_list[:,:,i]):\n",
    "            label_index.append(i)\n",
    "            continue\n",
    "    return np.array(label_index)\n",
    "\n",
    "def image_size_normalize(raw_data, size):\n",
    "    #选出有标记的图片并resize到相应尺寸\n",
    "    img_width, img_height, img_channel = size\n",
    "    \n",
    "    labeled_img_list = []\n",
    "    mask_list = []\n",
    "    \n",
    "    for patient_i in range(len(raw_data)):\n",
    "\n",
    "        img_i = raw_data[patient_i]['video'] # Shape: [IMG_WIDTH1, IMG_HEIGHT1, Frame_Num1]\n",
    "        mask_i = raw_data[patient_i]['label']\n",
    "        label_index = is_labeled(mask_i)\n",
    "        labeled_img_i = img_i[:,:,label_index]\n",
    "        labeled_mask_i = mask_i[:,:,label_index]\n",
    "        \n",
    "        for frame_j in range(labeled_mask_i.shape[2]):\n",
    "            img_j = labeled_img_i[:,:,frame_j] # [IMG_WIDTH2, IMG_HEIGHT2, Frame_Num2]\n",
    "            mask_j = labeled_mask_i[:,:,frame_j]\n",
    "            mask_j_digi = np.zeros(mask_j.shape)\n",
    "            mask_j_digi[mask_j] = 1\n",
    "            if(img_j.shape[0]!= IMG_WIDTH or img_j.shape[1]!= IMG_HEIGHT):\n",
    "                img_j = cv2.resize(img_j,(img_width, img_height))\n",
    "                mask_j_digi = cv2.resize(mask_j_digi,(img_width, img_height))\n",
    "            labeled_img_list.append(img_j)\n",
    "            mask_list.append(mask_j_digi)\n",
    "            \n",
    "    return np.array(labeled_img_list).reshape(-1,img_width, img_height, img_channel),np.array(mask_list).reshape(-1,img_width, img_height, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从训练集中选出所有label过的图像并resize到指定大小\n",
    "img_labeled, mask = image_size_normalize(train_data, (IMG_WIDTH,IMG_HEIGHT,IMG_CHANNELS))  # OutPut Shape: [Labeled_Frame_Num, IMG_WIDTH2, IMG_HEIGHT2, IMG_CHANNEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 256, 256, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_labeled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1Model Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(train_data)):\n",
    "#     print(train_data[i]['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(train_data)):\n",
    "#     print(len(is_labeled(train_data[i]['label'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# from skimage.io import imread, imshow\n",
    "# from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 256, 256, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 16) 160         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256, 256, 16) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 16) 2320        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 32) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 32) 9248        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   36928       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 128)  147584      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 256)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 256)  590080      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 32, 128)  131200      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 256)  0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 128)  295040      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 128)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 128)  147584      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 64)   32832       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64, 64, 64)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 64)   36928       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 32) 8224        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128, 128, 32) 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 32) 9248        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 16) 2064        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 256, 256, 16) 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 16) 2320        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 1)  17          conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,940,817\n",
      "Trainable params: 1,940,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 23:26:06.414327: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-17 23:26:06.414410: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#Contraction path\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "#Expansive path \n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    " \n",
    "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    " \n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 23:26:06.745696: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-17 23:26:06.745871: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 23:26:07.124086: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 9s 342ms/step - loss: 0.2090 - accuracy: 0.9871\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 6s 319ms/step - loss: 0.0614 - accuracy: 0.9883\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 6s 318ms/step - loss: 0.0430 - accuracy: 0.9883\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 6s 319ms/step - loss: 0.0317 - accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 6s 319ms/step - loss: 0.0240 - accuracy: 0.9883\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 6s 319ms/step - loss: 0.0208 - accuracy: 0.9884\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 6s 319ms/step - loss: 0.0183 - accuracy: 0.9893\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 6s 319ms/step - loss: 0.0170 - accuracy: 0.9904\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 6s 320ms/step - loss: 0.0166 - accuracy: 0.9908\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 6s 319ms/step - loss: 0.0164 - accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(img_labeled, mask, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def video_make(name, image_list, mask_list,  img_size =(112, 112)):\n",
    "\n",
    "    fps = 24 #视频每秒24帧\n",
    "    size = img_size #需要转为视频的图片的尺寸\n",
    "\n",
    "    #视频保存在当前目录下\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')    \n",
    "    video = cv2.VideoWriter(name+\".avi\",fourcc, fps,size, False)\n",
    "    #draw stuff that goes on every frame here\n",
    "    for frame_i in range(image_list.shape[2]):\n",
    "        img = (image_list[:,:,frame_i])\n",
    "        mask = mask_list[:,:,frame_i]\n",
    "        img[mask] = 255\n",
    "        img_mat = cv2.Mat(img)\n",
    "        video.write(img)\n",
    "    video.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Conclusion（things to be done for improvement）  \n",
    "4.1 如上可见，随着epoch增加, accuracy波动很大，网络不是很work。 不清楚是数据量不够，网络复杂度不够， 还是iter比较小（纯ml小白）  \n",
    "    如果是数据量不够， 或许需要用tracking的办法增加数据量\n",
    "4.2 需要做cross-validation的预测版本\n",
    "4.3 由于数据集中， 属于MV的像素点很少，和类别不平衡问题很像， 最好能增大 MV区域误识别的错误权重\n",
    "4.4 预测的可视化实现"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
