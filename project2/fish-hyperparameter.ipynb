{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fish: Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from biosppy.signals import ecg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/df/qjssdfqd3f52ltwv16hkg4kh0000gn/T/ipykernel_8258/2174170344.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxtest\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m_concatenate_chunks\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 )\n\u001b[1;32m    386\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarning_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xtrain = pd.read_csv(\"X_train.csv\")\n",
    "xtrain.drop(\"id\", axis=1, inplace = True)\n",
    "\n",
    "xtest =  pd.read_csv(\"X_test.csv\")\n",
    "xtest.drop(\"id\", axis=1, inplace = True)\n",
    "\n",
    "ytrain = pd.read_csv(\"y_train.csv\")\n",
    "ytrain.drop(\"id\", axis=1, inplace = True)\n",
    "\n",
    "print(xtrain.shape, xtest.shape, ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_sqrd_diff(rpeaks):\n",
    "    diff = np.diff(rpeaks)\n",
    "    mean_sqrd = np.mean(diff*diff)\n",
    "    return mean_sqrd\n",
    "\n",
    "def obtain_features(signal, sampling_rate):\n",
    "    \n",
    "    # features obtained from biosppy\n",
    "    ts, filtered, rpeaks, templates_ts, templates, heart_rate_ts, heart_rate = ecg.ecg(signal, sampling_rate, show = False)\n",
    "    \n",
    "    # Correct R-peak locations to the maximum --- introduce some tolerance level\n",
    "    rpeaks = ecg.correct_rpeaks(signal = signal, rpeaks = rpeaks, sampling_rate = sampling_rate, tol = 0.01)  \n",
    "    \n",
    "    # extracting values of R-peaks -- Note: rpeaks gives only indices for R-peaks location\n",
    "    peak_values = signal[rpeaks]\n",
    "    \n",
    "    # Set heart rates to array of nans if contains no elements, otherwise min and max are not defined\n",
    "    if len(heart_rate) == 0:\n",
    "        heart_rate = np.array([np.nan, np.nan])\n",
    "    if len(heart_rate_ts) == 0:\n",
    "        heart_rate_ts = np.array([np.nan, np.nan])\n",
    "    \n",
    "    # Add a bunch of features\n",
    "    feats = np.array([])\n",
    "    feats = np.append(feats, np.mean(peak_values))\n",
    "    feats = np.append(feats, np.median(peak_values))\n",
    "    feats = np.append(feats, np.min(peak_values))\n",
    "    feats = np.append(feats, np.max(peak_values))\n",
    "    feats = np.append(feats, np.std(peak_values))\n",
    "    feats = np.append(feats, np.mean(rpeaks))\n",
    "    feats = np.append(feats, np.median(rpeaks))\n",
    "    feats = np.append(feats, np.min(rpeaks))\n",
    "    feats = np.append(feats, np.max(rpeaks))\n",
    "    feats = np.append(feats, np.std(rpeaks))\n",
    "    feats = np.append(feats, np.sqrt(mean_sqrd_diff(rpeaks)))\n",
    "    feats = np.append(feats, np.mean(np.diff(rpeaks)))\n",
    "    feats = np.append(feats, np.median(np.diff(rpeaks)))\n",
    "    feats = np.append(feats, np.min(np.diff(rpeaks)))\n",
    "    feats = np.append(feats, np.max(np.diff(rpeaks)))\n",
    "    feats = np.append(feats, np.std(np.diff(rpeaks)))\n",
    "    feats = np.append(feats, np.mean(templates, axis = 0))\n",
    "    feats = np.append(feats, np.median(templates, axis = 0))\n",
    "    feats = np.append(feats, np.min(templates, axis=0))\n",
    "    feats = np.append(feats, np.max(templates, axis=0))\n",
    "    feats = np.append(feats, np.std(templates, axis = 0))\n",
    "    feats = np.append(feats, np.mean(heart_rate))\n",
    "    feats = np.append(feats, np.median(heart_rate))\n",
    "    feats = np.append(feats, np.min(heart_rate))\n",
    "    feats = np.append(feats, np.max(heart_rate))\n",
    "    feats = np.append(feats, np.std(heart_rate))\n",
    "    feats = np.append(feats, np.mean(heart_rate_ts))\n",
    "    feats = np.append(feats, np.median(heart_rate_ts))\n",
    "    feats = np.append(feats, np.min(heart_rate_ts))\n",
    "    feats = np.append(feats, np.max(heart_rate_ts))\n",
    "    feats = np.append(feats, np.std(heart_rate_ts))\n",
    "    # Once again check, if heart_rate arrays contain one element min and max of differences will return error\n",
    "    if len(heart_rate) == 1:\n",
    "        heart_rate = np.array([np.nan, np.nan])\n",
    "    if len(heart_rate_ts) == 1:\n",
    "        heart_rate_ts = np.array([np.nan, np.nan])\n",
    "    feats = np.append(feats, np.mean(np.diff(heart_rate)))\n",
    "    feats = np.append(feats, np.median(np.diff(heart_rate)))\n",
    "    feats = np.append(feats, np.min(np.diff(heart_rate)))\n",
    "    feats = np.append(feats, np.max(np.diff(heart_rate)))\n",
    "    feats = np.append(feats, np.std(np.diff(heart_rate)))\n",
    "    feats = np.append(feats, np.mean(np.diff(heart_rate_ts)))\n",
    "    feats = np.append(feats, np.median(np.diff(heart_rate_ts)))\n",
    "    feats = np.append(feats, np.min(np.diff(heart_rate_ts)))\n",
    "    feats = np.append(feats, np.max(np.diff(heart_rate_ts)))\n",
    "    feats = np.append(feats, np.std(np.diff(heart_rate_ts)))\n",
    "    \n",
    "    #feats = np.append(feats, np.abs(np.fft.rfft(np.mean(templates, axis=0), axis=0))[0:45] # adding FFT (choose only half of entries)\n",
    "    '''removed fft -- no improvements by adding it'''\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(xtrain.shape[0]):\n",
    "    if i == 0:\n",
    "        row = np.array(xtrain.iloc[i].dropna())\n",
    "        X_train = [obtain_features(row, 300)]\n",
    "    else: \n",
    "        row = np.array(xtrain.iloc[i].dropna())\n",
    "        X_train = np.append(X_train, [obtain_features(row, 300)], axis = 0)\n",
    "    \n",
    "for i in np.arange(xtest.shape[0]):\n",
    "    if i == 0:\n",
    "        row = np.array(xtest.iloc[i].dropna())\n",
    "        X_test = [obtain_features(row, 300)]\n",
    "    else: \n",
    "        row = np.array(xtest.iloc[i].dropna())\n",
    "        X_test = np.append(X_test, [obtain_features(row, 300)], axis = 0)\n",
    "\n",
    "y_train = np.ravel(np.array(ytrain.values))    \n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "use random subset of initial dataframe X for model selection  \n",
    "'''\n",
    "\n",
    "X_train = pd.DataFrame(X_train) \n",
    "X_train['y'] = y_train\n",
    "X_sub = pd.DataFrame(X_train).sample(frac = 0.40, replace = False, axis = 0)\n",
    "y_sub = X_sub['y']\n",
    "X_sub = X_sub.drop('y', axis = 1).values\n",
    "X_train = X_train.drop('y', axis = 1)\n",
    "print(y_sub.shape, X_sub.shape)\n",
    "\n",
    "'''define score function'''\n",
    "scorer_f1 = make_scorer(f1_score, greater_is_better = True, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## SVC APPROACH -- GRID-SEARCH CV\n",
    "\n",
    "steps = [(\"impute\", SimpleImputer()),\n",
    "            (\"scaler\", preprocessing.StandardScaler()), \n",
    "            (\"classifier\", SVC())]\n",
    "pipeline = Pipeline(steps = steps)\n",
    "\n",
    "parameters = {\"impute__strategy\": [\"mean\", \"median\", \"constant\"],\n",
    "              \"impute__fill_value\": [0],\n",
    "              \"classifier__kernel\": [\"rbf\", \"poly\"],\n",
    "              \"classifier__gamma\": [\"auto\"],\n",
    "              \"classifier__C\": [15,30,45,60,75],  \n",
    "              \"classifier__class_weight\": [\"balanced\"],\n",
    "              \"classifier__degree\": [2,4,6,8]\n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(pipeline, parameters, cv = 5, scoring = scorer_f1, verbose = 2)\n",
    "\n",
    "grid.fit(X, y)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "estimator = SVC(C = grid.best_params_['classifier__C'], gamma = 'auto', \n",
    "                class_weight = 'balanced', \n",
    "                kernel = grid.best_params_['classifier__kernel'], \n",
    "                degree = grid.best_params_['classifier__degree'])\n",
    "\n",
    "estimator.fit(xtrain_scaled, y)\n",
    "pred = estimator.predict(xtest_scaled)\n",
    "make_submission(\"prediction_trial.csv\", pred)\n",
    "'''\n",
    "\n",
    "'''\n",
    "Gradient Boosting APPROACH -- GRID-SEARCH CV\n",
    "''' \n",
    "\n",
    "# steps = [(\"impute\", SimpleImputer()),\n",
    "#          (\"scaler\", StandardScaler()), \n",
    "#          (\"classifier\", GradientBoostingClassifier())]\n",
    "# pipeline = Pipeline(steps = steps)\n",
    "\n",
    "# parameters = {\"impute__strategy\": [\"mean\", \"median\", \"constant\"],\n",
    "#               \"impute__fill_value\": [0],\n",
    "#               \"classifier__max_depth\": [3,4,5,6,7,8],\n",
    "#               \"classifier__n_estimators\": [200,250,300],\n",
    "#               \"classifier__learning_rate\": [0.1,0.08,0.05,0.03],\n",
    "#               \"classifier__max_features\": [40,50,60]\n",
    "#              }\n",
    "\n",
    "# grid = GridSearchCV(pipeline, parameters, cv = 2, scoring = scorer_f1, verbose = 1)\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# print(grid.best_score_)\n",
    "# print(grid.best_params_)\n",
    "\n",
    "\n",
    "## XGB APPROACH -- GRID-SEARCH CV\n",
    "\n",
    "\n",
    "steps = [(\"impute\", SimpleImputer()),\n",
    "            (\"scaler\", preprocessing.StandardScaler()), \n",
    "            (\"classifier\", xgb.XGBClassifier())]\n",
    "pipeline = Pipeline(steps = steps)\n",
    "\n",
    "parameters = {\"impute__strategy\": [\"mean\", \"median\", \"constant\"],\n",
    "              \"impute__fill_value\": [0],\n",
    "              \"classifier__max_depth\": [5,10,15],\n",
    "              \"classifier__n_estimators\": [200],\n",
    "              \"classifier__learning_rate\": [0.05,0.1],\n",
    "              \"classifier__max_features\": [20,40]\n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(pipeline, parameters, cv = 2, scoring = scorer_f1, verbose = 1)\n",
    "\n",
    "grid.fit(X_sub, y_sub)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
