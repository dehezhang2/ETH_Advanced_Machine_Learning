{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, targets):\n",
    "    ious = []\n",
    "    for p, t in zip(predictions, targets):\n",
    "        assert p['name'] == t['name']\n",
    "        prediction = np.array(p['prediction'], dtype=bool)\n",
    "        target = np.array(t['label'], dtype=bool)\n",
    "\n",
    "        assert target.shape == prediction.shape\n",
    "        overlap = prediction*target\n",
    "        union = prediction + target\n",
    "\n",
    "        ious.append(overlap.sum()/float(union.sum()))\n",
    "    \n",
    "    print(\"Median IOU: \", np.median(ious))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = load_zipped_pickle(\"train.pkl\")\n",
    "test_data = load_zipped_pickle(\"test.pkl\")\n",
    "samples = load_zipped_pickle(\"sample.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据结构：  \n",
    "    train_data[1-65]包含65个病人的数据, 前46个是amateur数据， 后19个是expert数据  \n",
    "    train_data[1]['video','label','dataset'...] , video是图片数组， label是MV mask，dataset代表是amateur还是expert  \n",
    "    train_data[1]['video'] shape: [IMG_WIDTH, IMG_HEIGHT, FRAME NUM]， label也一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583, 628)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_img = train_data[60]['label'][:,:,24]\n",
    "# zero_img = np.zeros(test_img.shape)\n",
    "# zero_img[test_img] = 255\n",
    "# zero_img_resize = cv2.resize(zero_img, (1000,1000))\n",
    "# zero_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"mask\", zero_img_resize)\n",
    "  \n",
    "# cv2.waitKey(0) \n",
    "\n",
    "# cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 样本图片大小\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到含有标记的帧\n",
    "#input: w*h*f_num\n",
    "def is_labeled(mask_list):\n",
    "    \n",
    "    label_index = []\n",
    "    for i in range((mask_list).shape[2]):\n",
    "        if(True in mask_list[:,:,i]):\n",
    "            label_index.append(i)\n",
    "            continue\n",
    "    return np.array(label_index)\n",
    "\n",
    "#选出有标记的图片并resize到相应尺寸\n",
    "#output: f_num*w*h*1\n",
    "def image_size_normalize(raw_data, size):\n",
    "    \n",
    "    img_width, img_height, img_channel = size\n",
    "    \n",
    "    labeled_img_list = []\n",
    "    mask_list = []\n",
    "    \n",
    "    for patient_i in range(len(raw_data)):\n",
    "\n",
    "        img_i = raw_data[patient_i]['video'] # Shape: [IMG_WIDTH1, IMG_HEIGHT1, Frame_Num1]\n",
    "        mask_i = raw_data[patient_i]['label']\n",
    "        label_index = is_labeled(mask_i)\n",
    "        labeled_img_i = img_i[:,:,label_index]\n",
    "        labeled_mask_i = mask_i[:,:,label_index]\n",
    "        \n",
    "        for frame_j in range(labeled_mask_i.shape[2]):\n",
    "            img_j = labeled_img_i[:,:,frame_j] # [IMG_WIDTH2, IMG_HEIGHT2, Frame_Num2]\n",
    "            mask_j = labeled_mask_i[:,:,frame_j]\n",
    "            mask_j_digi = np.zeros(mask_j.shape)\n",
    "            mask_j_digi[mask_j] = 1\n",
    "            if(img_j.shape[0]!= IMG_WIDTH or img_j.shape[1]!= IMG_HEIGHT):\n",
    "                img_j = cv2.resize(img_j,(img_width, img_height))\n",
    "                mask_j_digi = cv2.resize(mask_j_digi,(img_width, img_height))\n",
    "            labeled_img_list.append(img_j)\n",
    "            mask_list.append(mask_j_digi)\n",
    "            \n",
    "    return np.array(labeled_img_list).reshape(-1,img_width, img_height, img_channel),np.array(mask_list).reshape(-1,img_width, img_height, 1)\n",
    "\n",
    "#选出所有的图片并resize到相应尺寸\n",
    "#output: f_num*w*h*1\n",
    "def image_size_normalize_no_label(raw_data, size):\n",
    "    img_width, img_height, img_channel = size\n",
    "    \n",
    "    labeled_img_list = []\n",
    "    mask_list = []\n",
    "    \n",
    "    for patient_i in range(len(raw_data)):\n",
    "\n",
    "        img_i = raw_data[patient_i]['video'] # Shape: [IMG_WIDTH1, IMG_HEIGHT1, Frame_Num1]\n",
    "        mask_i = raw_data[patient_i]['label']\n",
    "        # label_index = is_labeled(mask_i)\n",
    "        # labeled_img_i = img_i[:,:,label_index]\n",
    "        # labeled_mask_i = mask_i[:,:,label_index]\n",
    "        \n",
    "        for frame_j in range(mask_i.shape[2]):\n",
    "            img_j = img_i[:,:,frame_j] # [IMG_WIDTH2, IMG_HEIGHT2, Frame_Num2]\n",
    "            mask_j = mask_i[:,:,frame_j]\n",
    "            mask_j_digi = np.zeros(mask_j.shape)\n",
    "            mask_j_digi[mask_j] = 1\n",
    "            if(img_j.shape[0]!= IMG_WIDTH or img_j.shape[1]!= IMG_HEIGHT):\n",
    "                img_j = cv2.resize(img_j,(img_width, img_height))\n",
    "                mask_j_digi = cv2.resize(mask_j_digi,(img_width, img_height))\n",
    "            labeled_img_list.append(img_j)\n",
    "            mask_list.append(mask_j_digi)\n",
    "            \n",
    "    return np.array(labeled_img_list).reshape(-1,img_width, img_height, img_channel),np.array(mask_list).reshape(-1,img_width, img_height, 1)\n",
    "\n",
    "#选出所有的图片并resize到相应尺寸\n",
    "#input: f_num*w*h*1\n",
    "def is_labeled_order2(mask_list):\n",
    "    \n",
    "    label_index = []\n",
    "    for i in range((mask_list).shape[0]):\n",
    "        if(True in mask_list[i,:,:,0]):\n",
    "            label_index.append(i)\n",
    "            continue\n",
    "    return np.array(label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从训练集中选出所有label过的图像并resize到指定大小\n",
    "img_labeled, mask = image_size_normalize(train_data, (IMG_WIDTH,IMG_HEIGHT,IMG_CHANNELS))  # OutPut Shape: [Labeled_Frame_Num, IMG_WIDTH2, IMG_HEIGHT2, IMG_CHANNEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1092,)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data[0]['box'][train_data[0]['box'] == True]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def video_make(name, image_list, mask_list,  img_size =(112, 112), only_MV = False):\n",
    "\n",
    "    fps = 24 #视频每秒24帧\n",
    "    size = img_size #需要转为视频的图片的尺寸\n",
    "\n",
    "    #视频保存在当前目录下\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')    \n",
    "    video = cv2.VideoWriter(name+\".avi\",fourcc, fps,size, False)\n",
    "    #draw stuff that goes on every frame here\n",
    "    for frame_i in range(image_list.shape[0]):\n",
    "        img = (image_list[frame_i,:,:,0])\n",
    "        mask = mask_list[frame_i,:,:,0]\n",
    "        img[mask>0.5] = 255\n",
    "        if(only_MV):\n",
    "            img[mask<0.5] = 0\n",
    "        img_mat = cv2.Mat(img)\n",
    "        video.write(img)\n",
    "    video.release()\n",
    "\n",
    "def image_process(src,threshold, DF_kernel = np.ones((4, 4), dtype=np.uint8)):\n",
    "    img_dst = np.zeros(src.shape,dtype=np.uint8)\n",
    "    cv2.bilateralFilter(src,dst = img_dst,d=5,sigmaColor = 20, sigmaSpace = 2)\n",
    "    img_threshold_idx = img_dst< threshold\n",
    "    img_dst[img_threshold_idx] = 0\n",
    "    # img_dst[~img_threshold_idx] = 100\n",
    "    img_dilation = cv2.dilate(img_dst, DF_kernel+1, 1)\n",
    "    img_erode = cv2.erode(img_dilation, DF_kernel, iterations=1)\n",
    "    \n",
    "\n",
    "    return img_erode\n",
    "\n",
    "def video_make_filtering(name, image_list, mask_list,  img_size =(112, 112), threshold = 0):\n",
    "\n",
    "    fps = 24 #视频每秒24帧\n",
    "    size = img_size #需要转为视频的图片的尺寸\n",
    "\n",
    "    #视频保存在当前目录下\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')    \n",
    "    video = cv2.VideoWriter(name+\".avi\",fourcc, fps,size, False)\n",
    "    #draw stuff that goes on every frame here\n",
    "    for frame_i in range(image_list.shape[0]):\n",
    "        img = (image_list[frame_i,:,:,0])\n",
    "        img_processed = image_process(img,20)\n",
    "        # img_processed = img\n",
    "        mask = mask_list[frame_i,:,:,0]\n",
    "        img_processed[mask>0.5] = 255\n",
    "        video.write(img_processed)\n",
    "    video.release()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train_data = train_data[50:52]\n",
    "video_list,mask_list = image_size_normalize_no_label(output_train_data, (256,256,1))\n",
    "# video_make(\"expert_show\", video_list, mask_list,  img_size =(256, 256),only_MV=False)\n",
    "video_make_filtering(\"expert_show\", video_list, mask_list,  img_size =(256, 256), threshold = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   6,  31, 107, 121, 159])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_labeled_order2(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LK_OpticalFlow(img1,img2,mask1, flate_size = 2):\n",
    "    \n",
    "    img_cur = img1\n",
    "    img_next = img2\n",
    "    mask_cur = mask1\n",
    "    flow = cv2.calcOpticalFlowFarneback(img_cur,img2,img_next, pyr_scale = 0.5, levels= 3, winsize = 8, iterations =5, poly_n = 5, poly_sigma = 1.2, flags = cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "\n",
    "    mask_next = np.zeros(mask_cur.shape)\n",
    "    for y_i in range(mask_cur.shape[0]):\n",
    "        for x_i in range(mask_cur.shape[1]):\n",
    "            if(mask_cur[y_i,x_i]>0.5):\n",
    "                new_y,new_x = int(y_i+flow[y_i,x_i,1]),int(x_i+flow[y_i,x_i,0])\n",
    "                mask_next[new_y,new_x] = 1\n",
    "    mask_next_DF = mask_next\n",
    "    mask_next_DF = cv2.dilate(mask_next, np.ones((flate_size, flate_size), dtype=np.uint8), 1)\n",
    "    mask_next_DF = cv2.erode(mask_next_DF, np.ones((flate_size, flate_size), dtype=np.uint8), 1)\n",
    "    # print(img_next[mask_next_DF>0.5].shape)\n",
    "    return mask_next_DF\n",
    "\n",
    "def tracking_result_evaluation(img,mask):\n",
    "    MV_points = img[mask>0.5]\n",
    "    MV_points = MV_points.reshape(-1)\n",
    "    return np.std(MV_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(523,)\n"
     ]
    }
   ],
   "source": [
    "img_cur = video_list[0,:,:,0]\n",
    "img_next = video_list[1,:,:,0]\n",
    "mask_cur = mask_list[0,:,:,0]\n",
    "mask_next = LK_OpticalFlow(img_cur,img_next,mask_cur, flate_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_next_output = img_next\n",
    "img_next_output[mask_next>0.5] = 255\n",
    "cv2.imwrite('./img/img_next_tracked3.png',img_next_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_next = np.zeros(mask_cur.shape)\n",
    "for y_i in range(mask_cur.shape[0]):\n",
    "    for x_i in range(mask_cur.shape[1]):\n",
    "        if(mask_cur[y_i,x_i]>0.5):\n",
    "            new_y,new_x = int(y_i+flow[y_i,x_i,1]),int(x_i+flow[y_i,x_i,0])\n",
    "            mask_next[new_y,new_x] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.99447870186591\n",
      "(508,)\n",
      "65.68514508681983\n",
      "42.04625266884282\n",
      "(508,)\n",
      "77.87362251897088\n",
      "57.170052029978294\n",
      "(508,)\n",
      "32.875596642642236\n",
      "47.14826560061548\n",
      "(508,)\n",
      "89.55753649807865\n",
      "48.47703581447694\n",
      "(508,)\n",
      "82.55198556764483\n",
      "50.3177457597662\n",
      "(508,)\n",
      "60.362790830386835\n"
     ]
    }
   ],
   "source": [
    "for index in is_labeled_order2(mask_list):\n",
    "    img_i = video_list[index,:,:,0]\n",
    "    mask_i = mask_list[index,:,:,0]\n",
    "    print('labeld frame: ', tracking_result_evaluation(img_i,mask_i))\n",
    "    img_i_next = video_list[index+1,:,:,0]\n",
    "    mask_next = LK_OpticalFlow(img_cur,img_next,mask_cur, flate_size = 2)\n",
    "    print('tracked frame: ', tracking_result_evaluation(img_i_next,mask_next))\n",
    "\n",
    "    img_i_labeld_output = img_i\n",
    "    img_i_labeld_output[mask_i>0.5] = 255\n",
    "    cv2.imwrite('./img/',index,'_cur.png',img_i_labeld_output)\n",
    "\n",
    "    img_next_output[mask_next>0.5] = 255\n",
    "    cv2.imwrite('./img/'+(index+1)+'_cur.png',img_i_next)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in is_labeled_order2(mask_list):\n",
    "    img_i = video_list[index,:,:,0]\n",
    "    mask_i = mask_list[index,:,:,0]\n",
    "    img_i_next = mask_list[index,:,:,0]\n",
    "    mask_next = LK_OpticalFlow(img_cur,img_next,mask_cur, flate_size = 2)\n",
    "    print(tracking_result_evaluation(img_i,mask_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Conclusion（things to be done for improvement）  \n",
    "4.1 如上可见，随着epoch增加, accuracy波动很大，网络不是很work。 不清楚是数据量不够，网络复杂度不够， 还是iter比较小（纯ml小白）  \n",
    "    如果是数据量不够， 或许需要用tracking的办法增加数据量\n",
    "4.2 需要做cross-validation的预测版本\n",
    "4.3 由于数据集中， 属于MV的像素点很少，和类别不平衡问题很像， 最好能增大 MV区域误识别的错误权重\n",
    "4.4 预测的可视化实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
